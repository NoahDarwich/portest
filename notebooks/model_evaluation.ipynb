{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pro-Test Model Evaluation & Comparison\n",
    "\n",
    "This notebook demonstrates the model training, evaluation, and comparison workflow for Pro-Test v2.0.\n",
    "\n",
    "## Contents\n",
    "1. Data Loading & Exploration\n",
    "2. Model Comparison (RF, XGBoost, LightGBM)\n",
    "3. Ensemble Training\n",
    "4. Feature Importance Analysis\n",
    "5. Model Registration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import sys\n",
    "\n",
    "sys.path.insert(0, \"..\")\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "from protest.models import (\n",
    "    EnsembleConfig,\n",
    "    EnsembleModel,\n",
    "    ModelConfig,\n",
    "    ModelRegistry,\n",
    "    ModelType,\n",
    "    compare_models,\n",
    "    print_comparison_report,\n",
    ")\n",
    "\n",
    "# Set style\n",
    "plt.style.use(\"seaborn-v0_8-whitegrid\")\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"Imports complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Loading & Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "df = pd.read_csv(\"../data/full_df.csv\")\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define features and targets\n",
    "FEATURE_COLUMNS = [\n",
    "    \"country\",\n",
    "    \"governorate\",\n",
    "    \"locationtypeend\",\n",
    "    \"demandtypeone\",\n",
    "    \"tacticprimary\",\n",
    "    \"violence\",\n",
    "]\n",
    "\n",
    "TARGET_COLUMNS = [\n",
    "    \"teargas\",\n",
    "    \"rubberbullets\",\n",
    "    \"liveammo\",\n",
    "    \"sticks\",\n",
    "    \"surround\",\n",
    "    \"cleararea\",\n",
    "    \"policerepress\",\n",
    "]\n",
    "\n",
    "# Handle combined_sizes\n",
    "if \"combined_sizes\" not in df.columns:\n",
    "    df[\"sizeestimate\"] = df[\"sizeestimate\"].fillna(-99)\n",
    "    df[\"sizeexact\"] = df[\"sizeexact\"].fillna(0)\n",
    "    df[\"combined_sizes\"] = df[\"sizeexact\"] + df[\"sizeestimate\"]\n",
    "\n",
    "# Replace unknown sizes with median\n",
    "median_size = df.loc[df[\"combined_sizes\"] > 0, \"combined_sizes\"].median()\n",
    "df.loc[df[\"combined_sizes\"] <= 0, \"combined_sizes\"] = median_size\n",
    "\n",
    "FEATURE_COLUMNS.append(\"combined_sizes\")\n",
    "\n",
    "# Filter available columns\n",
    "available_features = [c for c in FEATURE_COLUMNS if c in df.columns]\n",
    "available_targets = [c for c in TARGET_COLUMNS if c in df.columns]\n",
    "\n",
    "print(f\"Features: {available_features}\")\n",
    "print(f\"Targets: {available_targets}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare X and y\n",
    "X = df[available_features].copy()\n",
    "y = df[available_targets].copy()\n",
    "\n",
    "# Convert targets to binary\n",
    "for col in y.columns:\n",
    "    y[col] = (y[col] > 0).astype(int)\n",
    "\n",
    "print(f\"X shape: {X.shape}\")\n",
    "print(f\"y shape: {y.shape}\")\n",
    "print(\"\\nTarget distribution:\")\n",
    "y.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize target distribution\n",
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "y.mean().plot(kind=\"bar\", ax=ax, color=\"steelblue\")\n",
    "ax.set_title(\"Target Variable Distribution (Positive Rate)\")\n",
    "ax.set_ylabel(\"Proportion\")\n",
    "ax.set_xticklabels(ax.get_xticklabels(), rotation=45, ha=\"right\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Model Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare all model types\n",
    "results = compare_models(\n",
    "    X,\n",
    "    y,\n",
    "    model_types=[ModelType.RANDOM_FOREST, ModelType.XGBOOST, ModelType.LIGHTGBM],\n",
    "    n_folds=5,\n",
    ")\n",
    "\n",
    "# Print comparison report\n",
    "report = print_comparison_report(results)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize comparison\n",
    "metrics_df = pd.DataFrame(\n",
    "    [\n",
    "        {\n",
    "            \"Model\": r.model_type.value,\n",
    "            \"Accuracy\": r.overall_metrics.accuracy,\n",
    "            \"Precision\": r.overall_metrics.precision,\n",
    "            \"Recall\": r.overall_metrics.recall,\n",
    "            \"F1\": r.overall_metrics.f1,\n",
    "        }\n",
    "        for r in results\n",
    "    ]\n",
    ")\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 5))\n",
    "metrics_df.set_index(\"Model\")[[\"Accuracy\", \"Precision\", \"Recall\", \"F1\"]].plot(kind=\"bar\", ax=ax)\n",
    "ax.set_title(\"Model Comparison - Overall Metrics\")\n",
    "ax.set_ylabel(\"Score\")\n",
    "ax.set_ylim(0, 1)\n",
    "ax.legend(loc=\"lower right\")\n",
    "plt.xticks(rotation=0)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Ensemble Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train ensemble model\n",
    "config = ModelConfig(\n",
    "    target_columns=available_targets,\n",
    "    feature_columns=available_features,\n",
    ")\n",
    "\n",
    "ensemble_config = EnsembleConfig(\n",
    "    model_types=[ModelType.RANDOM_FOREST, ModelType.XGBOOST, ModelType.LIGHTGBM],\n",
    "    weights=[0.4, 0.35, 0.25],  # Weighted based on comparison results\n",
    "    voting=\"soft\",\n",
    ")\n",
    "\n",
    "ensemble = EnsembleModel(config=config, ensemble_config=ensemble_config)\n",
    "ensemble.fit(X, y)\n",
    "\n",
    "print(\"Ensemble trained!\")\n",
    "print(f\"Model ID: {ensemble.metadata.model_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test predictions with confidence\n",
    "sample = X.iloc[:5]\n",
    "mean_proba, std_proba = ensemble.predict_proba_with_confidence(sample)\n",
    "\n",
    "print(\"Sample predictions with confidence intervals:\")\n",
    "for i, target in enumerate(available_targets):\n",
    "    if i < len(mean_proba):\n",
    "        prob = mean_proba[i][0, 1]  # Probability of positive class\n",
    "        std = std_proba[i][0, 1]  # Standard deviation\n",
    "        print(f\"  {target}: {prob:.3f} Â± {std:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Feature Importance Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get feature importance\n",
    "importance = ensemble.get_feature_importance()\n",
    "\n",
    "# Plot top 20 features\n",
    "top_features = dict(list(importance.items())[:20])\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "pd.Series(top_features).plot(kind=\"barh\", ax=ax, color=\"steelblue\")\n",
    "ax.set_title(\"Top 20 Feature Importances (Ensemble)\")\n",
    "ax.set_xlabel(\"Importance\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Model Registration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Register model\n",
    "registry = ModelRegistry(\"../models/registry\")\n",
    "\n",
    "version = registry.register_model(\n",
    "    ensemble,\n",
    "    name=\"protest_predictor\",\n",
    "    description=\"Ensemble model (RF+XGB+LGBM) for protest outcome prediction\",\n",
    "    tags={\"type\": \"ensemble\", \"targets\": \",\".join(available_targets)},\n",
    ")\n",
    "\n",
    "print(f\"Registered model version: {version.version}\")\n",
    "print(f\"Artifact path: {version.artifact_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List registered models\n",
    "models = registry.list_models()\n",
    "for name, versions in models.items():\n",
    "    print(f\"\\n{name}:\")\n",
    "    for v in versions:\n",
    "        print(f\"  - {v.version} ({v.stage}) - {v.created_at}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Promote to production\n",
    "registry.promote_model(\"protest_predictor\", version.version, \"production\")\n",
    "print(f\"Promoted {version.version} to production!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook demonstrated:\n",
    "1. Loading and preparing protest event data\n",
    "2. Comparing Random Forest, XGBoost, and LightGBM models\n",
    "3. Training a weighted ensemble model\n",
    "4. Getting predictions with confidence intervals\n",
    "5. Analyzing feature importance\n",
    "6. Registering and promoting models\n",
    "\n",
    "The ensemble model combines the strengths of all three algorithms for more robust predictions."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
